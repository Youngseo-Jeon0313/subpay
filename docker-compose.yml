---
version: '3.8'
services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow_db
    volumes: [postgres_data:/var/lib/postgresql/data]
    networks: [airflow_network]
  redis:
    image: redis:7.4.3
    expose: [6379]
    healthcheck:
      test: [CMD, redis-cli, ping]
      interval: 10s
      timeout: 30s
      retries: 50
    restart: always
    networks: [airflow_network]
  mysql:
    image: mysql:8.0
    container_name: subpay-db
    ports: [3309:3306]
    environment:
      TZ: Asia/Seoul
      MYSQL_PASSWORD: subpay
      MYSQL_DATABASE: subpay
      MYSQL_ROOT_PASSWORD: subpay
    expose: ['3306']
    networks: [airflow_network]
  api:
    build:
      context: back
      dockerfile: Dockerfile
    ports: [8080:8080]
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://subpay-db:3306/subpay
      SPRING_DATASOURCE_USERNAME: root
      SPRING_DATASOURCE_PASSWORD: subpay
      SPRING_JPA_HIBERNATE_DDL_AUTO: update
      SPRING_JPA_SHOW_SQL: 'true'
      SPRING_JPA_PROPERTIES_HIBERNATE_DIALECT: org.hibernate.dialect.MySQL8Dialect
    depends_on: [mysql]
    networks: [airflow_network]
    restart: always
  airflow-init:
    image: apache/airflow:2.8.1
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/airflow/dags
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/airflow/plugins
      AIRFLOW__CORE__BASE_LOG_FOLDER: /opt/airflow/airflow/logs
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow_db
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow_db
    volumes: [./airflow:/opt/airflow/airflow]
    entrypoint: [bash, -c]
    command: >
      "airflow db init &&
       airflow users create --username admin --password admin --firstname Admin --lastname
      User --role Admin --email admin@example.com"
    networks: [airflow_network]
    depends_on: [postgres, redis]
  airflow-webserver:
    image: apache/airflow:2.8.1
    ports: [8082:8080]
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/airflow/dags
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/airflow/plugins
      AIRFLOW__CORE__BASE_LOG_FOLDER: /opt/airflow/airflow/logs
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow_db
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow_db
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    volumes: [./airflow:/opt/airflow/airflow]
    command: webserver
    networks: [airflow_network]
  airflow-scheduler:
    image: apache/airflow:2.8.1
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/airflow/dags
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/airflow/plugins
      AIRFLOW__CORE__BASE_LOG_FOLDER: /opt/airflow/airflow/logs
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow_db
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow_db
    volumes: [./airflow:/opt/airflow/airflow]
    command: scheduler
    depends_on: [airflow-webserver]
    networks: [airflow_network]
  airflow-worker:
    image: apache/airflow:2.8.1
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/airflow/dags
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/airflow/plugins
      AIRFLOW__CORE__BASE_LOG_FOLDER: /opt/airflow/airflow/logs
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow_db
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow_db
    volumes:
      - ./airflow:/opt/airflow/airflow
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      bash -c "
      apt-get update &&
      apt-get install -y docker.io &&
      airflow celery worker"
    user: root
    depends_on: [airflow-scheduler]
    networks: [airflow_network]
  flower:
    image: apache/airflow:2.8.1
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/airflow/dags
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/airflow/plugins
      AIRFLOW__CORE__BASE_LOG_FOLDER: /opt/airflow/airflow/logs
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow_db
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow_db
    ports: [5556:5555]
    command: celery flower
    depends_on: [redis]
    networks: [airflow_network]
volumes:
  postgres_data:
    driver: local
networks:
  airflow_network:
    driver: bridge
